"use strict";(self.webpackChunkcode_docs=self.webpackChunkcode_docs||[]).push([[53],{1109:a=>{a.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Pyspark","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Install Pyspark","href":"/second-documentation/docs/pyspark/Install pyspark","docId":"pyspark/Install pyspark"},{"type":"link","label":"M\xf4 h\xecnh ho\u1ea1t \u0111\u1ed9ng c\u1ee7a pyspark","href":"/second-documentation/docs/pyspark/M\xf4 h\xecnh Spark","docId":"pyspark/M\xf4 h\xecnh Spark"},{"type":"link","label":"RDD v\xe0 DataFrame","href":"/second-documentation/docs/pyspark/RDD v\xe0 DataFrame","docId":"pyspark/RDD v\xe0 DataFrame"},{"type":"link","label":"Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u","href":"/second-documentation/docs/pyspark/Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u","docId":"pyspark/Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u"},{"type":"link","label":"PySpark\'s data analysis","href":"/second-documentation/docs/pyspark/Data Analysis","docId":"pyspark/Data Analysis"}],"href":"/second-documentation/docs/category/pyspark"},{"type":"link","label":"Tutorial Intro","href":"/second-documentation/docs/intro","docId":"intro"}]},"docs":{"intro":{"id":"intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes.","sidebar":"tutorialSidebar"},"pyspark/Data Analysis":{"id":"pyspark/Data Analysis","title":"PySpark\'s data analysis","description":"","sidebar":"tutorialSidebar"},"pyspark/Install pyspark":{"id":"pyspark/Install pyspark","title":"Install Pyspark","description":"1. Install JDK","sidebar":"tutorialSidebar"},"pyspark/M\xf4 h\xecnh Spark":{"id":"pyspark/M\xf4 h\xecnh Spark","title":"M\xf4 h\xecnh ho\u1ea1t \u0111\u1ed9ng c\u1ee7a pyspark","description":"mohinhhoatdongcuapyspark","sidebar":"tutorialSidebar"},"pyspark/Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u":{"id":"pyspark/Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u","title":"Quy t\u1eafc x\u1eed l\xed d\u1eef li\u1ec7u","description":"DataFrame c\u1ee7a pyspark l\xe0 immutable. Do \u0111\xf3, khi ta th\u1ef1c hi\u1ec7n 1 mutation, ta ph\u1ea3i ghi \u0111\xe8 l\xean bi\u1ebfn hi\u1ec7n t\u1ea1i. L\xfac n\xe0y, qu\xe1 tr\xecnh debug r\u1ea5t l\xe0 kh\xf3. Do \u0111\xf3, ta ph\u1ea3i c\xf3 1 b\u1ed9 quy t\u1eafc, khi n\xe0o t\u1ea1o bi\u1ebfn m\u1edbi, khi n\xe0o ghi \u0111\xe8, khi n\xe0o t\u1ea1o columns m\u1edbi ...","sidebar":"tutorialSidebar"},"pyspark/RDD v\xe0 DataFrame":{"id":"pyspark/RDD v\xe0 DataFrame","title":"RDD v\xe0 DataFrame","description":"Resilient Distributed Dataset l\xe0 th\xe0nh ph\u1ea7n core nh\u1ea5t c\u1ee7a spark. N\xf3 g\u1ed3m c\xe1c t\xednh ch\u1ea5t sau","sidebar":"tutorialSidebar"}}}')}}]);